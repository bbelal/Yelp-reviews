{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing reviews of an Italian restaurant on Yelp with Spacy\n",
    "<img src=\"https://i.imgur.com/OVNE60Z.jpeg\" alt=\"Meatball Sub\" width=\"450\"/>\n",
    "\n",
    "## Task description\n",
    "The challenge is to identify the worst items on the restaurant's menu in order to fix them. This could be done by identity menu items with the worst reviews on Yelp. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>lDJIaF4eYRF4F7g6Zb9euw</td>\n",
       "      <td>lb0QUR5bc4O-Am4hNq9ZGg</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I used to work food service and my manager at ...</td>\n",
       "      <td>2013-01-27 17:54:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>vvIzf3pr8lTqE_AOsxmgaA</td>\n",
       "      <td>MAmijW4ooUzujkufYYLMeQ</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We have been trying Eggplant sandwiches all ov...</td>\n",
       "      <td>2015-04-15 04:50:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>UF-JqzMczZ8vvp_4tPK3bQ</td>\n",
       "      <td>slfi6gf_qEYTXy90Sw93sg</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Amazing Steak and Cheese... Better than any Ph...</td>\n",
       "      <td>2011-03-20 00:57:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>geUJGrKhXynxDC2uvERsLw</td>\n",
       "      <td>N_-UepOzAsuDQwOUtfRFGw</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Although I have been going to DeFalco's for ye...</td>\n",
       "      <td>2018-07-17 01:48:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>aPctXPeZW3kDq36TRm-CqA</td>\n",
       "      <td>139hD7gkZVzSvSzDPwhNNw</td>\n",
       "      <td>r5PLDU-4mSbde5XekTXSCA</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Highs: Ambience, value, pizza and deserts. Thi...</td>\n",
       "      <td>2018-01-21 10:52:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   review_id                 user_id             business_id  \\\n",
       "109   lDJIaF4eYRF4F7g6Zb9euw  lb0QUR5bc4O-Am4hNq9ZGg  r5PLDU-4mSbde5XekTXSCA   \n",
       "1013  vvIzf3pr8lTqE_AOsxmgaA  MAmijW4ooUzujkufYYLMeQ  r5PLDU-4mSbde5XekTXSCA   \n",
       "1204  UF-JqzMczZ8vvp_4tPK3bQ  slfi6gf_qEYTXy90Sw93sg  r5PLDU-4mSbde5XekTXSCA   \n",
       "1251  geUJGrKhXynxDC2uvERsLw  N_-UepOzAsuDQwOUtfRFGw  r5PLDU-4mSbde5XekTXSCA   \n",
       "1354  aPctXPeZW3kDq36TRm-CqA  139hD7gkZVzSvSzDPwhNNw  r5PLDU-4mSbde5XekTXSCA   \n",
       "\n",
       "      stars  useful  funny  cool  \\\n",
       "109       4       2      0     0   \n",
       "1013      4       0      0     0   \n",
       "1204      5       1      0     0   \n",
       "1251      1       0      0     0   \n",
       "1354      2       0      0     0   \n",
       "\n",
       "                                                   text                date  \n",
       "109   I used to work food service and my manager at ... 2013-01-27 17:54:54  \n",
       "1013  We have been trying Eggplant sandwiches all ov... 2015-04-15 04:50:56  \n",
       "1204  Amazing Steak and Cheese... Better than any Ph... 2011-03-20 00:57:45  \n",
       "1251  Although I have been going to DeFalco's for ye... 2018-07-17 01:48:23  \n",
       "1354  Highs: Ambience, value, pizza and deserts. Thi... 2018-01-21 10:52:58  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load in the data from JSON file\n",
    "data = pd.read_json('input/restaurant.json')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The owner also gave you this list of menu items and common alternate spellings.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu = [\"Cheese Steak\", \"Cheesesteak\", \"Steak and Cheese\", \"Italian Combo\", \"Tiramisu\", \"Cannoli\",\n",
    "        \"Chicken Salad\", \"Chicken Spinach Salad\", \"Meatball\", \"Pizza\", \"Pizzas\", \"Spaghetti\",\n",
    "        \"Bruchetta\", \"Eggplant\", \"Italian Beef\", \"Purista\", \"Pasta\", \"Calzones\",  \"Calzone\",\n",
    "        \"Italian Sausage\", \"Chicken Cutlet\", \"Chicken Parm\", \"Chicken Parmesan\", \"Gnocchi\",\n",
    "        \"Chicken Pesto\", \"Turkey Sandwich\", \"Turkey Breast\", \"Ziti\", \"Portobello\", \"Reuben\",\n",
    "        \"Mozzarella Caprese\",  \"Corned Beef\", \"Garlic Bread\", \"Pastrami\", \"Roast Beef\",\n",
    "        \"Tuna Salad\", \"Lasagna\", \"Artichoke Salad\", \"Fettuccini Alfredo\", \"Chicken Parmigiana\",\n",
    "        \"Grilled Veggie\", \"Grilled Veggies\", \"Grilled Vegetable\", \"Mac and Cheese\", \"Macaroni\",  \n",
    "         \"Prosciutto\", \"Salami\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Create matcher\n",
    "\n",
    "We will group reviews by what menu items they mention, and then calculate the average rating for reviews that mentioned each item. We can tell which foods are mentioned in reviews with low scores, so the restaurant can fix the recipe or remove those foods from the menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "# Load the SpaCy model\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "# Create the PhraseMatcher object. The tokenizer is the first argument. Use attr = 'LOWER' to make consistent capitalization\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "\n",
    "# Create a list of tokens for each item in the menu\n",
    "menu_tokens_list = [nlp(item) for item in menu]\n",
    "\n",
    "# Add the item patterns to the matcher. \n",
    "\n",
    "\n",
    "matcher.add(\"MENU\",            # Just a name for the set of rules we're matching to\n",
    "            menu_tokens_list  \n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Matching on the whole dataset\n",
    "\n",
    "Now we will run the matcher over the whole dataset and collect ratings for each menu item. Each review has a rating, `review.stars`. For each item that appears in the review text (`review.text`), will append the review's rating to a list of ratings for that item. The lists are kept in a dictionary `item_ratings`.\n",
    "\n",
    "To get the matched phrases, we can reference the `PhraseMatcher` documentation for the structure of each match object:\n",
    "\n",
    ">A list of `(match_id, start, end)` tuples, describing the matches. A match tuple describes a span `doc[start:end]`. The `match_id` is the ID of the added match pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# item_ratings is a dictionary of lists. If a key doesn't exist in item_ratings,\n",
    "# the key is added with an empty list as the value.\n",
    "item_ratings = defaultdict(list)\n",
    "\n",
    "for idx, review in data.iterrows():\n",
    "    doc = nlp(review.text)\n",
    "    # Using the matcher from the previous cell\n",
    "    matches = matcher(doc)\n",
    "    \n",
    "    # Create a set of the items found in the review text\n",
    "    found_items = set(list([doc[match[1]:match[2]].lower_ for match in matches ]))\n",
    "    \n",
    "    # Update item_ratings with rating for each item in found_items\n",
    "    # Transform the item strings to lowercase to make it case insensitive\n",
    "    for item in found_items:\n",
    "        item_ratings[item].append(review.stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: What's the worst reviewed item?\n",
    "\n",
    "Using these item ratings, we will find the menu item with the worst average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chicken cutlet\n",
      "3.4\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean ratings for each menu item as a dictionary\n",
    "mean_ratings = {item: sum(ratings)/len(ratings) for item, ratings in item_ratings.items()}\n",
    "\n",
    "# Find the worst item, and write it as a string in worst_item. This can be multiple lines of code if you want.\n",
    "worst_item = sorted(mean_ratings, key=mean_ratings.get)[0]\n",
    "\n",
    "print(worst_item)\n",
    "print(mean_ratings[worst_item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Are counts important here?\n",
    "\n",
    "Similar to the mean ratings, we will calculate the number of reviews for each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst rated menu items:\n",
      "chicken cutlet       Ave rating: 3.40 \tcount: 10\n",
      "turkey sandwich      Ave rating: 3.80 \tcount: 5\n",
      "spaghetti            Ave rating: 3.89 \tcount: 36\n",
      "italian beef         Ave rating: 3.92 \tcount: 25\n",
      "tuna salad           Ave rating: 4.00 \tcount: 5\n",
      "macaroni             Ave rating: 4.00 \tcount: 5\n",
      "italian combo        Ave rating: 4.05 \tcount: 21\n",
      "garlic bread         Ave rating: 4.13 \tcount: 39\n",
      "roast beef           Ave rating: 4.14 \tcount: 7\n",
      "eggplant             Ave rating: 4.16 \tcount: 69\n",
      "\n",
      "\n",
      "Best rated menu items:\n",
      "chicken pesto        Ave rating: 4.56 \tcount: 27\n",
      "chicken salad        Ave rating: 4.60 \tcount: 5\n",
      "purista              Ave rating: 4.67 \tcount: 63\n",
      "prosciutto           Ave rating: 4.68 \tcount: 50\n",
      "reuben               Ave rating: 4.75 \tcount: 4\n",
      "steak and cheese     Ave rating: 4.89 \tcount: 9\n",
      "artichoke salad      Ave rating: 5.00 \tcount: 5\n",
      "fettuccini alfredo   Ave rating: 5.00 \tcount: 6\n",
      "turkey breast        Ave rating: 5.00 \tcount: 1\n",
      "corned beef          Ave rating: 5.00 \tcount: 2\n"
     ]
    }
   ],
   "source": [
    "counts = {item: len(ratings) for item, ratings in item_ratings.items()}\n",
    "\n",
    "item_counts = sorted(counts, key=counts.get, reverse=True)\n",
    "    \n",
    "\n",
    "sorted_ratings = sorted(mean_ratings, key=mean_ratings.get)\n",
    "\n",
    "print(\"Worst rated menu items:\")\n",
    "for item in sorted_ratings[:10]:\n",
    "    print(f\"{item:20} Ave rating: {mean_ratings[item]:.2f} \\tcount: {counts[item]}\")\n",
    "    \n",
    "print(\"\\n\\nBest rated menu items:\")\n",
    "for item in sorted_ratings[-10:]:\n",
    "    print(f\"{item:20} Ave rating: {mean_ratings[item]:.2f} \\tcount: {counts[item]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The less data we have for any specific item, the less we can trust that the average rating is the \"real\" sentiment of the customers. This is fairly common sense. If more people tell us the same thing, we're more likely to believe it.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
